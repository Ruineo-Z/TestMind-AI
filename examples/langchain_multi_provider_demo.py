#!/usr/bin/env python3
"""
LangChainå¤šä¾›åº”å•†éœ€æ±‚æå–å™¨æ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨OpenAIã€Geminiã€Ollamaä¸‰ä¸ªä¾›åº”å•†è¿›è¡Œéœ€æ±‚æå–
"""
import asyncio
import os
from typing import Dict, Any

from app.requirements_parser.extractors.langchain_extractor import LangChainExtractor, AIProvider
from app.requirements_parser.models.document import Document, DocumentType


def create_sample_document() -> Document:
    """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£"""
    content = """# åœ¨çº¿å­¦ä¹ å¹³å°éœ€æ±‚æ–‡æ¡£

## é¡¹ç›®æ¦‚è¿°
å¼€å‘ä¸€ä¸ªç°ä»£åŒ–çš„åœ¨çº¿å­¦ä¹ å¹³å°ï¼Œæ”¯æŒå¤šç§å­¦ä¹ æ–¹å¼å’Œäº’åŠ¨åŠŸèƒ½ã€‚

## åŠŸèƒ½éœ€æ±‚

### 1. ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ
- ç”¨æˆ·æ³¨å†Œå’Œç™»å½•
- ç”¨æˆ·èµ„æ–™ç®¡ç†
- è§’è‰²æƒé™ç®¡ç†ï¼ˆå­¦ç”Ÿã€æ•™å¸ˆã€ç®¡ç†å‘˜ï¼‰
- å¯†ç é‡ç½®åŠŸèƒ½

### 2. è¯¾ç¨‹ç®¡ç†
- è¯¾ç¨‹åˆ›å»ºå’Œç¼–è¾‘
- è¯¾ç¨‹åˆ†ç±»å’Œæ ‡ç­¾
- è¯¾ç¨‹å‘å¸ƒå’Œä¸‹æ¶
- è¯¾ç¨‹è¯„ä»·ç³»ç»Ÿ

### 3. å­¦ä¹ åŠŸèƒ½
- è§†é¢‘æ’­æ”¾å™¨
- åœ¨çº¿æµ‹éªŒç³»ç»Ÿ
- å­¦ä¹ è¿›åº¦è·Ÿè¸ª
- ç¬”è®°åŠŸèƒ½
- è®¨è®ºåŒº

### 4. æ”¯ä»˜ç³»ç»Ÿ
- è¯¾ç¨‹è´­ä¹°
- å¤šç§æ”¯ä»˜æ–¹å¼
- è®¢å•ç®¡ç†
- é€€æ¬¾å¤„ç†

## éåŠŸèƒ½æ€§éœ€æ±‚

### æ€§èƒ½è¦æ±‚
- ç³»ç»Ÿå“åº”æ—¶é—´ä¸è¶…è¿‡2ç§’
- æ”¯æŒ1000å¹¶å‘ç”¨æˆ·
- è§†é¢‘åŠ è½½æ—¶é—´ä¸è¶…è¿‡5ç§’

### å®‰å…¨è¦æ±‚
- ç”¨æˆ·æ•°æ®åŠ å¯†å­˜å‚¨
- HTTPSé€šä¿¡
- é˜²SQLæ³¨å…¥
- å®šæœŸå®‰å…¨å®¡è®¡

### å¯ç”¨æ€§è¦æ±‚
- ç³»ç»Ÿå¯ç”¨æ€§99.9%
- æ”¯æŒç§»åŠ¨ç«¯è®¿é—®
- å¤šè¯­è¨€æ”¯æŒ
"""
    
    return Document(
        title="åœ¨çº¿å­¦ä¹ å¹³å°éœ€æ±‚æ–‡æ¡£",
        content=content,
        document_type=DocumentType.MARKDOWN
    )


async def demo_provider_extraction(provider: AIProvider, document: Document) -> Dict[str, Any]:
    """æ¼”ç¤ºç‰¹å®šä¾›åº”å•†çš„éœ€æ±‚æå–"""
    print(f"\n{'='*60}")
    print(f"ä½¿ç”¨ {provider.value.upper()} ä¾›åº”å•†è¿›è¡Œéœ€æ±‚æå–")
    print(f"{'='*60}")
    
    try:
        # æ ¹æ®ä¾›åº”å•†åˆ›å»ºæå–å™¨
        if provider == AIProvider.OPENAI:
            # æ³¨æ„ï¼šéœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡
            extractor = LangChainExtractor(
                provider=AIProvider.OPENAI,
                model="gpt-3.5-turbo",
                temperature=0.1
            )
        elif provider == AIProvider.GEMINI:
            # æ³¨æ„ï¼šéœ€è¦è®¾ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡
            extractor = LangChainExtractor(
                provider=AIProvider.GEMINI,
                model="gemini-1.5-pro",
                temperature=0.1
            )
        elif provider == AIProvider.OLLAMA:
            # Ollama ä¸éœ€è¦APIå¯†é’¥ï¼Œä½†éœ€è¦æœ¬åœ°è¿è¡ŒOllamaæœåŠ¡
            extractor = LangChainExtractor(
                provider=AIProvider.OLLAMA,
                model="qwen2.5:3b",
                ollama_url="http://localhost:11434",
                temperature=0.1
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¾›åº”å•†: {provider}")
        
        print(f"âœ… æˆåŠŸåˆå§‹åŒ– {provider.value} æå–å™¨")
        print(f"   æ¨¡å‹: {extractor.model}")
        print(f"   æ¸©åº¦: {extractor.temperature}")
        
        # æ‰§è¡Œéœ€æ±‚æå–
        print(f"\nğŸ”„ å¼€å§‹æå–éœ€æ±‚...")
        result = await extractor.extract_with_accuracy(document, expected_count=10)
        
        # æ˜¾ç¤ºç»“æœ
        requirements = result['requirements']
        print(f"âœ… æå–å®Œæˆï¼")
        print(f"   æå–æ•°é‡: {result['extracted_count']}")
        print(f"   å‡†ç¡®ç‡: {result['accuracy']:.2%}")
        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2%}")
        
        # æ˜¾ç¤ºå‰3ä¸ªéœ€æ±‚çš„è¯¦ç»†ä¿¡æ¯
        print(f"\nğŸ“‹ éœ€æ±‚è¯¦æƒ…ï¼ˆå‰3ä¸ªï¼‰:")
        for i, req in enumerate(requirements[:3], 1):
            print(f"\n{i}. {req.title}")
            print(f"   ID: {req.id}")
            print(f"   ç±»å‹: {req.type}")
            print(f"   ä¼˜å…ˆçº§: {req.priority}")
            print(f"   æè¿°: {req.description[:100]}...")
            print(f"   éªŒæ”¶æ ‡å‡†: {len(req.acceptance_criteria)} é¡¹")
            print(f"   æå–å™¨: {req.extracted_by}")
        
        # è´¨é‡éªŒè¯
        quality_result = extractor.validate_extraction_quality(requirements)
        print(f"\nğŸ“Š è´¨é‡è¯„ä¼°:")
        print(f"   è´¨é‡åˆ†æ•°: {quality_result['quality_score']:.2%}")
        print(f"   å‘ç°é—®é¢˜: {len(quality_result['issues'])} ä¸ª")
        print(f"   æ”¹è¿›å»ºè®®: {len(quality_result['recommendations'])} ä¸ª")
        
        return {
            'provider': provider.value,
            'success': True,
            'requirements_count': len(requirements),
            'accuracy': result['accuracy'],
            'confidence': result['confidence'],
            'quality_score': quality_result['quality_score']
        }
        
    except Exception as e:
        print(f"âŒ {provider.value} æå–å¤±è´¥: {e}")
        return {
            'provider': provider.value,
            'success': False,
            'error': str(e)
        }


async def compare_providers():
    """æ¯”è¾ƒä¸åŒä¾›åº”å•†çš„æå–æ•ˆæœ"""
    print("ğŸš€ LangChainå¤šä¾›åº”å•†éœ€æ±‚æå–å™¨æ¼”ç¤º")
    print("æ”¯æŒçš„ä¾›åº”å•†: OpenAI, Google Gemini, Ollama")
    
    # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
    document = create_sample_document()
    print(f"\nğŸ“„ æ–‡æ¡£ä¿¡æ¯:")
    print(f"   æ ‡é¢˜: {document.title}")
    print(f"   ç±»å‹: {document.document_type}")
    print(f"   å†…å®¹é•¿åº¦: {len(document.content)} å­—ç¬¦")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    print(f"\nğŸ”§ ç¯å¢ƒæ£€æŸ¥:")
    openai_key = os.environ.get('OPENAI_API_KEY')
    google_key = os.environ.get('GOOGLE_API_KEY')
    print(f"   OPENAI_API_KEY: {'âœ… å·²è®¾ç½®' if openai_key else 'âŒ æœªè®¾ç½®'}")
    print(f"   GOOGLE_API_KEY: {'âœ… å·²è®¾ç½®' if google_key else 'âŒ æœªè®¾ç½®'}")
    print(f"   OllamaæœåŠ¡: å‡è®¾åœ¨ localhost:11434 è¿è¡Œ")
    
    # æµ‹è¯•æ‰€æœ‰å¯ç”¨çš„ä¾›åº”å•†
    results = []
    
    # æµ‹è¯• Ollamaï¼ˆé€šå¸¸æœ€å®¹æ˜“è®¾ç½®ï¼‰
    print(f"\nğŸ¯ å¼€å§‹æµ‹è¯•ä¾›åº”å•†...")
    ollama_result = await demo_provider_extraction(AIProvider.OLLAMA, document)
    results.append(ollama_result)
    
    # æµ‹è¯• OpenAIï¼ˆå¦‚æœæœ‰APIå¯†é’¥ï¼‰
    if openai_key:
        openai_result = await demo_provider_extraction(AIProvider.OPENAI, document)
        results.append(openai_result)
    else:
        print(f"\nâš ï¸  è·³è¿‡ OpenAI æµ‹è¯•ï¼ˆæœªè®¾ç½®APIå¯†é’¥ï¼‰")
    
    # æµ‹è¯• Geminiï¼ˆå¦‚æœæœ‰APIå¯†é’¥ï¼‰
    if google_key:
        gemini_result = await demo_provider_extraction(AIProvider.GEMINI, document)
        results.append(gemini_result)
    else:
        print(f"\nâš ï¸  è·³è¿‡ Gemini æµ‹è¯•ï¼ˆæœªè®¾ç½®APIå¯†é’¥ï¼‰")
    
    # æ±‡æ€»æ¯”è¾ƒç»“æœ
    print(f"\n{'='*60}")
    print("ğŸ“Š ä¾›åº”å•†æ¯”è¾ƒç»“æœ")
    print(f"{'='*60}")
    
    successful_results = [r for r in results if r['success']]
    
    if successful_results:
        print(f"{'ä¾›åº”å•†':<12} {'éœ€æ±‚æ•°é‡':<8} {'å‡†ç¡®ç‡':<8} {'ç½®ä¿¡åº¦':<8} {'è´¨é‡åˆ†æ•°':<10}")
        print("-" * 60)
        
        for result in successful_results:
            print(f"{result['provider']:<12} "
                  f"{result['requirements_count']:<8} "
                  f"{result['accuracy']:.1%}    "
                  f"{result['confidence']:.1%}    "
                  f"{result['quality_score']:.1%}")
        
        # æ‰¾å‡ºæœ€ä½³ä¾›åº”å•†
        best_provider = max(successful_results, 
                          key=lambda x: (x['accuracy'] + x['confidence'] + x['quality_score']) / 3)
        print(f"\nğŸ† æ¨èä¾›åº”å•†: {best_provider['provider'].upper()}")
        print(f"   ç»¼åˆè¯„åˆ†æœ€é«˜ï¼Œé€‚åˆå½“å‰éœ€æ±‚æå–ä»»åŠ¡")
    else:
        print("âŒ æ²¡æœ‰ä¾›åº”å•†æµ‹è¯•æˆåŠŸ")
        print("è¯·æ£€æŸ¥:")
        print("1. OllamaæœåŠ¡æ˜¯å¦åœ¨è¿è¡Œ (http://localhost:11434)")
        print("2. APIå¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®")
        print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")


async def main():
    """ä¸»å‡½æ•°"""
    try:
        await compare_providers()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        print(f"\nâœ¨ æ¼”ç¤ºç»“æŸ")


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(main())
