#!/usr/bin/env python3
"""
ç”Ÿäº§çº§æ–‡æ¡£è§£ææµ‹è¯•æ‰§è¡Œè„šæœ¬
æ”¯æŒä¸åŒçº§åˆ«çš„æµ‹è¯•æ‰§è¡Œå’Œè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š
"""
import argparse
import time
import json
import sys
from pathlib import Path
from datetime import datetime
import subprocess
import psutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class ProductionTestRunner:
    """ç”Ÿäº§çº§æµ‹è¯•æ‰§è¡Œå™¨"""
    
    def __init__(self):
        self.project_root = project_root
        self.test_results = []
        self.start_time = None
        
    def run_tests(self, level: str = "all", verbose: bool = True):
        """æ‰§è¡Œæµ‹è¯•"""
        self.start_time = time.time()
        
        print("ğŸ­ TestMind AI - ç”Ÿäº§çº§æ–‡æ¡£è§£æåŠŸèƒ½æµ‹è¯•")
        print("=" * 60)
        print(f"æµ‹è¯•çº§åˆ«: {level}")
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Pythonç‰ˆæœ¬: {sys.version}")
        print(f"å·¥ä½œç›®å½•: {self.project_root}")
        
        # æ£€æŸ¥ç¯å¢ƒ
        self._check_environment()
        
        # æ‰§è¡Œæµ‹è¯•
        if level == "all":
            self._run_all_levels()
        else:
            self._run_specific_level(level)
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()
    
    def _check_environment(self):
        """æ£€æŸ¥æµ‹è¯•ç¯å¢ƒ"""
        print("\nğŸ” ç¯å¢ƒæ£€æŸ¥")
        print("-" * 30)
        
        # æ£€æŸ¥ä¾èµ–
        try:
            import fastapi
            import pytest
            import psutil
            print("âœ… æ ¸å¿ƒä¾èµ–åŒ…å·²å®‰è£…")
        except ImportError as e:
            print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
            sys.exit(1)
        
        # æ£€æŸ¥æµ‹è¯•æ•°æ®
        test_data_dir = self.project_root / "tests" / "integration" / "test_data"
        if not test_data_dir.exists():
            print("âš ï¸  æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºåŸºç¡€æµ‹è¯•æ•°æ®")
            self._create_test_data()
        else:
            print("âœ… æµ‹è¯•æ•°æ®ç›®å½•å­˜åœ¨")
        
        # æ£€æŸ¥ç³»ç»Ÿèµ„æº
        memory = psutil.virtual_memory()
        print(f"ğŸ’¾ å¯ç”¨å†…å­˜: {memory.available / 1024 / 1024 / 1024:.1f} GB")
        print(f"ğŸ–¥ï¸  CPUæ ¸å¿ƒæ•°: {psutil.cpu_count()}")
    
    def _create_test_data(self):
        """åˆ›å»ºåŸºç¡€æµ‹è¯•æ•°æ®"""
        test_data_dir = self.project_root / "tests" / "integration" / "test_data"
        test_data_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºmarkdownæµ‹è¯•ç›®å½•
        markdown_dir = test_data_dir / "markdown"
        markdown_dir.mkdir(exist_ok=True)
        
        print("ğŸ“ åˆ›å»ºåŸºç¡€æµ‹è¯•æ•°æ®å®Œæˆ")
    
    def _run_all_levels(self):
        """è¿è¡Œæ‰€æœ‰çº§åˆ«çš„æµ‹è¯•"""
        levels = [
            ("1", "å¿«é€ŸéªŒè¯æµ‹è¯•", "< 30ç§’"),
            ("2", "å…¨é¢åŠŸèƒ½æµ‹è¯•", "2-5åˆ†é’Ÿ"),
            ("3", "æ€§èƒ½å‹åŠ›æµ‹è¯•", "5-10åˆ†é’Ÿ"),
            ("4", "ç”¨æˆ·éªŒæ”¶æµ‹è¯•", "ç«¯åˆ°ç«¯åœºæ™¯")
        ]
        
        for level, name, duration in levels:
            print(f"\nğŸ“‹ Level {level}: {name} (é¢„è®¡è€—æ—¶: {duration})")
            print("-" * 50)
            self._run_specific_level(level)
    
    def _run_specific_level(self, level: str):
        """è¿è¡Œç‰¹å®šçº§åˆ«çš„æµ‹è¯•"""
        test_file = self.project_root / "tests" / "integration" / "test_document_parsing_production.py"
        
        if not test_file.exists():
            print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return
        
        # æ„å»ºpytestå‘½ä»¤
        cmd = [
            sys.executable, "-m", "pytest",
            str(test_file),
            "-v",
            "--tb=short"
        ]

        if level == "1":
            cmd.append("-k TestLevel1QuickValidation")
        elif level == "2":
            cmd.append("-k TestLevel2ComprehensiveFunctionality")
        elif level == "3":
            cmd.append("-k TestLevel3PerformanceStress")
        elif level == "4":
            cmd.append("-k TestLevel4UserAcceptance")
        
        start_time = time.time()
        
        try:
            # æ‰§è¡Œæµ‹è¯•
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )
            
            duration = time.time() - start_time
            
            # è®°å½•ç»“æœ
            test_result = {
                "level": level,
                "duration": duration,
                "return_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "success": result.returncode == 0
            }
            
            self.test_results.append(test_result)
            
            # æ˜¾ç¤ºç»“æœ
            if result.returncode == 0:
                print(f"âœ… Level {level} æµ‹è¯•é€šè¿‡ (è€—æ—¶: {duration:.1f}ç§’)")
            else:
                print(f"âŒ Level {level} æµ‹è¯•å¤±è´¥ (è€—æ—¶: {duration:.1f}ç§’)")
                print("é”™è¯¯è¾“å‡º:")
                print(result.stderr)
            
        except subprocess.TimeoutExpired:
            print(f"â° Level {level} æµ‹è¯•è¶…æ—¶")
            self.test_results.append({
                "level": level,
                "duration": 600,
                "return_code": -1,
                "success": False,
                "error": "æµ‹è¯•è¶…æ—¶"
            })
        
        except Exception as e:
            print(f"ğŸ’¥ Level {level} æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}")
            self.test_results.append({
                "level": level,
                "duration": 0,
                "return_code": -1,
                "success": False,
                "error": str(e)
            })
    
    def _generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        total_duration = time.time() - self.start_time
        
        print("\nğŸ“Š æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ€»è€—æ—¶: {total_duration:.1f}ç§’")
        print(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ç»Ÿè®¡ç»“æœ
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r["success"])
        failed_tests = total_tests - passed_tests
        
        print(f"\nğŸ“ˆ æµ‹è¯•ç»Ÿè®¡:")
        print(f"  æ€»æµ‹è¯•çº§åˆ«: {total_tests}")
        print(f"  é€šè¿‡: {passed_tests}")
        print(f"  å¤±è´¥: {failed_tests}")
        print(f"  æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%" if total_tests > 0 else "  æˆåŠŸç‡: 0%")
        
        # è¯¦ç»†ç»“æœ
        print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for result in self.test_results:
            status = "âœ… PASS" if result["success"] else "âŒ FAIL"
            print(f"  Level {result['level']}: {status} ({result['duration']:.1f}s)")
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = self.project_root / "test_reports" / f"production_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        report_file.parent.mkdir(exist_ok=True)
        
        report_data = {
            "timestamp": datetime.now().isoformat(),
            "total_duration": total_duration,
            "summary": {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "failed_tests": failed_tests,
                "success_rate": passed_tests/total_tests if total_tests > 0 else 0
            },
            "results": self.test_results
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # ç»™å‡ºå»ºè®®
        self._provide_recommendations()
    
    def _provide_recommendations(self):
        """æä¾›æµ‹è¯•å»ºè®®"""
        print(f"\nğŸ’¡ å»ºè®®:")
        
        failed_levels = [r["level"] for r in self.test_results if not r["success"]]
        
        if not failed_levels:
            print("  ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼ç³»ç»Ÿå·²å‡†å¤‡å¥½ç”Ÿäº§éƒ¨ç½²ã€‚")
        else:
            print(f"  âš ï¸  ä»¥ä¸‹çº§åˆ«çš„æµ‹è¯•å¤±è´¥: {', '.join(failed_levels)}")
            
            if "1" in failed_levels:
                print("  ğŸ”§ Level 1å¤±è´¥è¡¨ç¤ºåŸºç¡€åŠŸèƒ½æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥APIå’Œæ ¸å¿ƒè§£æå™¨")
            if "2" in failed_levels:
                print("  ğŸ”§ Level 2å¤±è´¥è¡¨ç¤ºå¤æ‚åœºæ™¯å¤„ç†æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µ")
            if "3" in failed_levels:
                print("  ğŸ”§ Level 3å¤±è´¥è¡¨ç¤ºæ€§èƒ½ä¸è¾¾æ ‡ï¼Œè¯·ä¼˜åŒ–ç®—æ³•å’Œèµ„æºä½¿ç”¨")
            if "4" in failed_levels:
                print("  ğŸ”§ Level 4å¤±è´¥è¡¨ç¤ºç”¨æˆ·ä½“éªŒæœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç«¯åˆ°ç«¯æµç¨‹")
        
        # æ€§èƒ½å»ºè®®
        slow_tests = [r for r in self.test_results if r.get("duration", 0) > 60]
        if slow_tests:
            print(f"  â° ä»¥ä¸‹æµ‹è¯•è€—æ—¶è¾ƒé•¿ï¼Œè€ƒè™‘ä¼˜åŒ–: {[r['level'] for r in slow_tests]}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ç”Ÿäº§çº§æ–‡æ¡£è§£æåŠŸèƒ½æµ‹è¯•")
    parser.add_argument(
        "--level",
        choices=["1", "2", "3", "4", "all"],
        default="all",
        help="æµ‹è¯•çº§åˆ« (1=å¿«é€ŸéªŒè¯, 2=å…¨é¢åŠŸèƒ½, 3=æ€§èƒ½å‹åŠ›, 4=ç”¨æˆ·éªŒæ”¶, all=å…¨éƒ¨)"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="è¯¦ç»†è¾“å‡º"
    )
    
    args = parser.parse_args()
    
    runner = ProductionTestRunner()
    runner.run_tests(level=args.level, verbose=args.verbose)


if __name__ == "__main__":
    main()
