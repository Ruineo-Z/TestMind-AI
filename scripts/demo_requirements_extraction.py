#!/usr/bin/env python3
"""
TestMind AI - éœ€æ±‚æå–æ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„æ–‡æ¡£è§£æ â†’ AIéœ€æ±‚æå–æµç¨‹
ä½¿ç”¨æ‚¨çš„Ollama + qwen3:4bé…ç½®
"""
import asyncio
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.requirements_parser.parsers.markdown_parser import MarkdownParser
from app.requirements_parser.extractors.langchain_extractor import LangChainExtractor, AIProvider
from app.requirements_parser.models.document import Document, DocumentType

async def demo_complete_workflow():
    """æ¼”ç¤ºå®Œæ•´çš„éœ€æ±‚æå–å·¥ä½œæµç¨‹"""
    print("ğŸš€ TestMind AI - éœ€æ±‚æå–æ¼”ç¤º")
    print("=" * 60)
    print("ä½¿ç”¨æŠ€æœ¯æ ˆï¼š")
    print("ğŸ“„ æ–‡æ¡£è§£æï¼šMarkdown Parser")
    print("ğŸ¤– AIæ¨¡å‹ï¼šOllama + qwen3:4b (å…è´¹æœ¬åœ°)")
    print("ğŸ”§ æ¡†æ¶ï¼šLangChain + FastAPI")
    print("=" * 60)
    
    # 1. åˆ›å»ºç¤ºä¾‹éœ€æ±‚æ–‡æ¡£
    print("\nğŸ“ æ­¥éª¤1ï¼šåˆ›å»ºç¤ºä¾‹éœ€æ±‚æ–‡æ¡£")
    
    sample_markdown = """# åœ¨çº¿æ•™è‚²å¹³å°éœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦

## é¡¹ç›®æ¦‚è¿°
å¼€å‘ä¸€ä¸ªé¢å‘K12æ•™è‚²çš„åœ¨çº¿å­¦ä¹ å¹³å°ï¼Œæ”¯æŒç›´æ’­è¯¾ç¨‹ã€ä½œä¸šç®¡ç†å’Œå­¦ä¹ è¿›åº¦è·Ÿè¸ªã€‚

## ç”¨æˆ·æ•…äº‹

### ä½œä¸ºå­¦ç”Ÿï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿè§‚çœ‹ç›´æ’­è¯¾ç¨‹
**éªŒæ”¶æ ‡å‡†ï¼š**
- æ”¯æŒé«˜æ¸…è§†é¢‘ç›´æ’­ï¼ˆ1080pï¼‰
- å»¶è¿Ÿå°äº3ç§’
- æ”¯æŒè¯¾ç¨‹å›æ”¾åŠŸèƒ½
- å¯ä»¥åœ¨è¯¾ç¨‹ä¸­æé—®å’Œäº’åŠ¨
- æ”¯æŒå¤šè®¾å¤‡åŒæ­¥è§‚çœ‹

**ä¼˜å…ˆçº§ï¼š** é«˜

### ä½œä¸ºè€å¸ˆï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿåˆ›å»ºå’Œç®¡ç†è¯¾ç¨‹
**éªŒæ”¶æ ‡å‡†ï¼š**
- å¯ä»¥åˆ›å»ºè¯¾ç¨‹å¤§çº²å’Œè¯¾ç¨‹è¡¨
- æ”¯æŒä¸Šä¼ è¯¾ä»¶å’Œæ•™å­¦èµ„æº
- å¯ä»¥å¸ƒç½®å’Œæ‰¹æ”¹ä½œä¸š
- èƒ½å¤ŸæŸ¥çœ‹å­¦ç”Ÿå­¦ä¹ è¿›åº¦
- æ”¯æŒè¯¾å ‚äº’åŠ¨å·¥å…·

**ä¼˜å…ˆçº§ï¼š** é«˜

### ä½œä¸ºå®¶é•¿ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿç›‘æ§å­©å­çš„å­¦ä¹ æƒ…å†µ
**éªŒæ”¶æ ‡å‡†ï¼š**
- å¯ä»¥æŸ¥çœ‹å­©å­çš„è¯¾ç¨‹å®‰æ’
- èƒ½å¤Ÿçœ‹åˆ°ä½œä¸šå®Œæˆæƒ…å†µ
- å¯ä»¥æŸ¥çœ‹å­¦ä¹ æ—¶é•¿ç»Ÿè®¡
- æ¥æ”¶å­¦ä¹ è¿›åº¦æŠ¥å‘Š
- å¯ä»¥ä¸è€å¸ˆæ²Ÿé€š

**ä¼˜å…ˆçº§ï¼š** ä¸­

## åŠŸèƒ½éœ€æ±‚

### 1. ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ
- æ”¯æŒå­¦ç”Ÿã€è€å¸ˆã€å®¶é•¿ä¸‰ç§è§’è‰²æ³¨å†Œ
- å®åè®¤è¯åŠŸèƒ½
- æƒé™ç®¡ç†å’Œè§’è‰²åˆ‡æ¢
- ä¸ªäººä¿¡æ¯ç®¡ç†

### 2. è¯¾ç¨‹ç®¡ç†ç³»ç»Ÿ
- è¯¾ç¨‹åˆ›å»ºå’Œç¼–è¾‘
- è¯¾ç¨‹åˆ†ç±»å’Œæœç´¢
- è¯¾ç¨‹è¯„ä»·å’Œæ¨è
- è¯¾ç¨‹èµ„æºç®¡ç†

### 3. ç›´æ’­æ•™å­¦ç³»ç»Ÿ
- å®æ—¶éŸ³è§†é¢‘ä¼ è¾“
- å±å¹•å…±äº«åŠŸèƒ½
- ç™½æ¿å·¥å…·
- è¯¾å ‚äº’åŠ¨ï¼ˆä¸¾æ‰‹ã€æŠ•ç¥¨ï¼‰
- è¯¾ç¨‹å½•åˆ¶å’Œå›æ”¾

### 4. ä½œä¸šç®¡ç†ç³»ç»Ÿ
- ä½œä¸šå‘å¸ƒå’Œæ”¶é›†
- åœ¨çº¿æ‰¹æ”¹å·¥å…·
- æˆç»©ç»Ÿè®¡å’Œåˆ†æ
- ä½œä¸šæé†’åŠŸèƒ½

### 5. å­¦ä¹ è¿›åº¦è·Ÿè¸ª
- å­¦ä¹ æ—¶é•¿ç»Ÿè®¡
- çŸ¥è¯†ç‚¹æŒæ¡åº¦åˆ†æ
- å­¦ä¹ æŠ¥å‘Šç”Ÿæˆ
- ä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®

## éåŠŸèƒ½éœ€æ±‚

### æ€§èƒ½è¦æ±‚
- ç³»ç»Ÿå“åº”æ—¶é—´ < 2ç§’
- æ”¯æŒ10000å¹¶å‘ç”¨æˆ·
- è§†é¢‘åŠ è½½æ—¶é—´ < 5ç§’
- 99.9%ç³»ç»Ÿå¯ç”¨æ€§

### å®‰å…¨è¦æ±‚
- ç”¨æˆ·æ•°æ®åŠ å¯†å­˜å‚¨
- æ”¯æŒHTTPSä¼ è¾“
- é˜²æ­¢è§†é¢‘ç›—å½•
- å®šæœŸå®‰å…¨å®¡è®¡

### å…¼å®¹æ€§è¦æ±‚
- æ”¯æŒä¸»æµæµè§ˆå™¨ï¼ˆChromeã€Firefoxã€Safariã€Edgeï¼‰
- æ”¯æŒç§»åŠ¨ç«¯ï¼ˆiOSã€Androidï¼‰
- æ”¯æŒå¹³æ¿è®¾å¤‡
- å‘ä¸‹å…¼å®¹æ—§ç‰ˆæœ¬æµè§ˆå™¨

### å¯æ‰©å±•æ€§è¦æ±‚
- æ”¯æŒæ°´å¹³æ‰©å±•
- æ¨¡å—åŒ–æ¶æ„è®¾è®¡
- æ”¯æŒç¬¬ä¸‰æ–¹é›†æˆ
- å›½é™…åŒ–æ”¯æŒ

## ç³»ç»Ÿçº¦æŸ
- å¿…é¡»ç¬¦åˆæ•™è‚²éƒ¨ç›¸å…³æ³•è§„
- ä¿æŠ¤æœªæˆå¹´äººéšç§
- å†…å®¹å®¡æ ¸æœºåˆ¶
- æ•°æ®æœ¬åœ°åŒ–å­˜å‚¨
"""
    
    print("âœ… ç¤ºä¾‹æ–‡æ¡£åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“Š æ–‡æ¡£é•¿åº¦ï¼š{len(sample_markdown)} å­—ç¬¦")
    
    # 2. è§£æMarkdownæ–‡æ¡£
    print("\nğŸ“„ æ­¥éª¤2ï¼šè§£æMarkdownæ–‡æ¡£")
    
    parser = MarkdownParser()
    document = parser.parse(sample_markdown)
    
    print("âœ… Markdownè§£æå®Œæˆ")
    print(f"ğŸ“‹ æ–‡æ¡£æ ‡é¢˜ï¼š{document.title}")
    print(f"ğŸ“‘ ç« èŠ‚æ•°é‡ï¼š{len(document.sections)}")
    print(f"ğŸ‘¥ ç”¨æˆ·æ•…äº‹ï¼š{len(document.user_stories)}")
    print(f"ğŸ”— é“¾æ¥æ•°é‡ï¼š{len(document.links)}")
    print(f"ğŸ“Š è¡¨æ ¼æ•°é‡ï¼š{len(document.tables)}")
    
    # 3. ä½¿ç”¨qwen3:4bæå–éœ€æ±‚
    print("\nğŸ¤– æ­¥éª¤3ï¼šAIéœ€æ±‚æå–ï¼ˆqwen3:4bï¼‰")
    
    extractor = LangChainExtractor(
        provider=AIProvider.OLLAMA,
        model="qwen3:4b",
        ollama_url="http://localhost:11434"
    )
    
    print("ğŸ”„ æ­£åœ¨åˆ†ææ–‡æ¡£å¹¶æå–éœ€æ±‚...")
    print("â³ è¿™å¯èƒ½éœ€è¦10-30ç§’ï¼Œè¯·ç¨å€™...")
    
    requirements = await extractor.extract_async(document)
    
    print(f"âœ… éœ€æ±‚æå–å®Œæˆï¼å…±æå– {len(requirements)} ä¸ªéœ€æ±‚")
    
    # 4. åˆ†ææå–ç»“æœ
    print("\nğŸ“Š æ­¥éª¤4ï¼šéœ€æ±‚åˆ†æç»“æœ")
    
    # æŒ‰ç±»å‹åˆ†ç»„
    functional_reqs = [r for r in requirements if r.type == "functional"]
    non_functional_reqs = [r for r in requirements if r.type == "non_functional"]
    user_stories = [r for r in requirements if r.type == "user_story"]
    
    print(f"ğŸ”§ åŠŸèƒ½éœ€æ±‚ï¼š{len(functional_reqs)} ä¸ª")
    print(f"âš¡ éåŠŸèƒ½éœ€æ±‚ï¼š{len(non_functional_reqs)} ä¸ª")
    print(f"ğŸ‘¤ ç”¨æˆ·æ•…äº‹ï¼š{len(user_stories)} ä¸ª")
    
    # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
    high_priority = [r for r in requirements if r.priority == "high"]
    medium_priority = [r for r in requirements if r.priority == "medium"]
    low_priority = [r for r in requirements if r.priority == "low"]
    
    print(f"ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼š{len(high_priority)} ä¸ª")
    print(f"ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼š{len(medium_priority)} ä¸ª")
    print(f"ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼š{len(low_priority)} ä¸ª")
    
    # 5. å±•ç¤ºè¯¦ç»†éœ€æ±‚
    print("\nğŸ“‹ æ­¥éª¤5ï¼šè¯¦ç»†éœ€æ±‚å±•ç¤º")
    
    for i, req in enumerate(requirements[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"\n{'='*50}")
        print(f"ğŸ“Œ éœ€æ±‚ {i}: {req.title}")
        print(f"ğŸ†” ID: {req.id}")
        print(f"ğŸ“ ç±»å‹: {req.type}")
        print(f"â­ ä¼˜å…ˆçº§: {req.priority}")
        print(f"ğŸ“„ æè¿°: {req.description}")
        if req.acceptance_criteria:
            print(f"âœ… éªŒæ”¶æ ‡å‡†:")
            for j, criteria in enumerate(req.acceptance_criteria, 1):
                print(f"   {j}. {criteria}")
        else:
            print("âœ… éªŒæ”¶æ ‡å‡†: æ— ")
    
    if len(requirements) > 5:
        print(f"\n... è¿˜æœ‰ {len(requirements) - 5} ä¸ªéœ€æ±‚æœªæ˜¾ç¤º")
    
    # 6. è´¨é‡è¯„ä¼°
    print("\nğŸ¯ æ­¥éª¤6ï¼šæå–è´¨é‡è¯„ä¼°")
    
    quality = extractor.validate_extraction_quality(requirements)
    
    print(f"ğŸ“Š è´¨é‡åˆ†æ•°: {quality['quality_score']:.2f}/1.0")
    print(f"âš ï¸  å‘ç°é—®é¢˜: {len(quality['issues'])} ä¸ª")
    print(f"ğŸ’¡ æ”¹è¿›å»ºè®®: {len(quality['recommendations'])} ä¸ª")
    
    if quality['issues']:
        print("\nâš ï¸  è´¨é‡é—®é¢˜:")
        for issue in quality['issues'][:3]:
            print(f"   â€¢ {issue}")
    
    if quality['recommendations']:
        print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for rec in quality['recommendations'][:3]:
            print(f"   â€¢ {rec}")
    
    # 7. å¯¼å‡ºç»“æœ
    print("\nğŸ’¾ æ­¥éª¤7ï¼šå¯¼å‡ºç»“æœ")
    
    # åˆ›å»ºéœ€æ±‚é›†åˆ
    collection = extractor.create_requirement_collection(requirements)
    
    # å¯¼å‡ºä¸ºJSON
    output_file = "extracted_requirements.json"
    requirements_data = []

    for req in requirements:
        req_dict = req.model_dump()
        # å¤„ç†datetimeåºåˆ—åŒ–
        if req_dict.get('created_at'):
            created_at = req_dict['created_at']
            req_dict['created_at'] = created_at.isoformat() if hasattr(created_at, 'isoformat') else str(created_at)
        if req_dict.get('updated_at'):
            updated_at = req_dict['updated_at']
            req_dict['updated_at'] = updated_at.isoformat() if hasattr(updated_at, 'isoformat') else str(updated_at)
        requirements_data.append(req_dict)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(requirements_data, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"âœ… éœ€æ±‚å·²å¯¼å‡ºåˆ°: {output_file}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   â€¢ æ€»éœ€æ±‚æ•°: {collection.total_count}")
    print(f"   â€¢ åŠŸèƒ½éœ€æ±‚: {collection.functional_count}")
    print(f"   â€¢ éåŠŸèƒ½éœ€æ±‚: {collection.non_functional_count}")
    print(f"   â€¢ ç”¨æˆ·æ•…äº‹: {collection.user_story_count}")
    
    # 8. æ€»ç»“
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    print("âœ… æˆåŠŸå±•ç¤ºäº†å®Œæ•´çš„éœ€æ±‚æå–æµç¨‹ï¼š")
    print("   1. ğŸ“„ Markdownæ–‡æ¡£è§£æ")
    print("   2. ğŸ¤– AIæ™ºèƒ½éœ€æ±‚æå–")
    print("   3. ğŸ“Š ç»“æ„åŒ–æ•°æ®è¾“å‡º")
    print("   4. ğŸ¯ è´¨é‡è¯„ä¼°å’ŒéªŒè¯")
    print("   5. ğŸ’¾ ç»“æœå¯¼å‡ºå’Œå­˜å‚¨")
    print("\nğŸ†“ ä½¿ç”¨çš„æ˜¯å®Œå…¨å…è´¹çš„æœ¬åœ°AIæ–¹æ¡ˆï¼")
    print("ğŸš€ æ‚¨å¯ä»¥å¼€å§‹å¤„ç†çœŸå®çš„éœ€æ±‚æ–‡æ¡£äº†ï¼")

async def main():
    """ä¸»å‡½æ•°"""
    try:
        await demo_complete_workflow()
        return 0
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("   1. ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ: ollama serve")
        print("   2. ç¡®ä¿qwen3:4bæ¨¡å‹å·²ä¸‹è½½: ollama list")
        print("   3. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç«¯å£11434")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
