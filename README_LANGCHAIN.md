# LangChainå¤šä¾›åº”å•†éœ€æ±‚æå–å™¨

åŸºäºLangChainæ¡†æ¶å®ç°çš„AIé©±åŠ¨éœ€æ±‚æå–å™¨ï¼Œæ”¯æŒOpenAIã€Google Geminiã€Ollamaä¸‰ä¸ªä¸»è¦AIä¾›åº”å•†ã€‚

## ğŸŒŸ ç‰¹æ€§

- **å¤šä¾›åº”å•†æ”¯æŒ**: æ— ç¼åˆ‡æ¢OpenAIã€Google Geminiã€Ollama
- **çœŸæ­£çš„LangChainé›†æˆ**: ä½¿ç”¨LangChainçš„ç»Ÿä¸€æŠ½è±¡è€Œéç›´æ¥è°ƒç”¨å„ä¾›åº”å•†SDK
- **å¼‚æ­¥å¤„ç†**: æ”¯æŒå¼‚æ­¥APIè°ƒç”¨å’Œæ‰¹é‡å¤„ç†
- **çµæ´»é…ç½®**: æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹ã€æ¸©åº¦å‚æ•°ç­‰
- **è´¨é‡è¯„ä¼°**: å†…ç½®å‡†ç¡®ç‡å’Œç½®ä¿¡åº¦è¯„ä¼°
- **æœ¬åœ°ä¼˜å…ˆ**: é»˜è®¤ä½¿ç”¨æœ¬åœ°Ollamaæ¨¡å‹ï¼Œæ— éœ€APIå¯†é’¥

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å®‰è£…LangChainç›¸å…³åŒ…
uv add langchain-ollama langchain-openai langchain-google-genai langchain-core langchain-community
```

### 2. åŸºæœ¬ä½¿ç”¨

```python
from app.requirements_parser.extractors.langchain_extractor import LangChainExtractor, AIProvider
from app.requirements_parser.models.document import Document, DocumentType

# åˆ›å»ºæ–‡æ¡£
document = Document(
    title="éœ€æ±‚æ–‡æ¡£",
    content="# ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ\n- ç”¨æˆ·æ³¨å†Œ\n- ç”¨æˆ·ç™»å½•",
    document_type=DocumentType.MARKDOWN
)

# ä½¿ç”¨Ollamaï¼ˆæœ¬åœ°æ¨¡å‹ï¼Œæ— éœ€APIå¯†é’¥ï¼‰
extractor = LangChainExtractor(
    provider=AIProvider.OLLAMA,
    model="qwen3:4b"  # ä½¿ç”¨æ‚¨æœ¬åœ°çš„æ¨¡å‹
)

# æå–éœ€æ±‚
requirements = extractor.extract(document)
print(f"æå–åˆ° {len(requirements)} ä¸ªéœ€æ±‚")
```

### 3. å¼‚æ­¥ä½¿ç”¨

```python
import asyncio

async def extract_requirements():
    # å¼‚æ­¥æå–
    requirements = await extractor.extract_async(document)
    
    # å¸¦å‡†ç¡®ç‡è¯„ä¼°
    result = await extractor.extract_with_accuracy(document, expected_count=5)
    print(f"å‡†ç¡®ç‡: {result['accuracy']:.2%}")
    print(f"ç½®ä¿¡åº¦: {result['confidence']:.2%}")

asyncio.run(extract_requirements())
```

## ğŸ”§ ä¾›åº”å•†é…ç½®

### Ollama (æ¨èï¼Œæœ¬åœ°è¿è¡Œ)

```python
extractor = LangChainExtractor(
    provider=AIProvider.OLLAMA,
    model="qwen3:4b",  # æˆ–å…¶ä»–æœ¬åœ°æ¨¡å‹
    ollama_url="http://localhost:11434"
)
```

**ä¼˜åŠ¿**: æ— éœ€APIå¯†é’¥ï¼Œæ•°æ®éšç§ï¼Œæˆæœ¬ä½
**è¦æ±‚**: æœ¬åœ°å®‰è£…Ollamaå’Œæ¨¡å‹

### OpenAI

```python
extractor = LangChainExtractor(
    provider=AIProvider.OPENAI,
    model="gpt-3.5-turbo",
    openai_api_key="your-api-key"  # æˆ–è®¾ç½®ç¯å¢ƒå˜é‡OPENAI_API_KEY
)
```

**ä¼˜åŠ¿**: é«˜è´¨é‡è¾“å‡ºï¼Œç¨³å®šå¯é 
**è¦æ±‚**: OpenAI APIå¯†é’¥

### Google Gemini

```python
extractor = LangChainExtractor(
    provider=AIProvider.GEMINI,
    model="gemini-1.5-pro",
    google_api_key="your-api-key"  # æˆ–è®¾ç½®ç¯å¢ƒå˜é‡GOOGLE_API_KEY
)
```

**ä¼˜åŠ¿**: å¤šæ¨¡æ€æ”¯æŒï¼Œæˆæœ¬æ•ˆç›Š
**è¦æ±‚**: Google APIå¯†é’¥

## ğŸ“ é¡¹ç›®ç»“æ„

```
app/requirements_parser/extractors/
â”œâ”€â”€ langchain_extractor.py          # ä¸»è¦çš„LangChainéœ€æ±‚æå–å™¨
â””â”€â”€ __init__.py

tests/unit/
â”œâ”€â”€ test_langchain_extractor.py     # å®Œæ•´çš„å¤šä¾›åº”å•†æµ‹è¯•å¥—ä»¶
â””â”€â”€ ...

examples/
â”œâ”€â”€ simple_langchain_demo.py        # ç®€å•æ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ langchain_multi_provider_demo.py # å¤šä¾›åº”å•†æ¯”è¾ƒæ¼”ç¤º
â””â”€â”€ ...

scripts/
â”œâ”€â”€ check_ollama_models.py          # Ollamaæ¨¡å‹æ£€æŸ¥å·¥å…·
â””â”€â”€ ...
```

## ğŸ§ª è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰LangChainæµ‹è¯•
uv run pytest tests/unit/test_langchain_extractor.py -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
uv run pytest tests/unit/test_langchain_extractor.py::TestLangChainMultiProvider::test_ollama_extract_async -v
```

## ğŸ¯ æ¼”ç¤ºè„šæœ¬

### ç®€å•æ¼”ç¤º
```bash
uv run python examples/simple_langchain_demo.py
```

### å¤šä¾›åº”å•†æ¯”è¾ƒ
```bash
uv run python examples/langchain_multi_provider_demo.py
```

### æ£€æŸ¥æœ¬åœ°æ¨¡å‹
```bash
uv run python scripts/check_ollama_models.py
```

## ğŸ” é«˜çº§åŠŸèƒ½

### æ‰¹é‡å¤„ç†

```python
documents = [doc1, doc2, doc3]
results = await extractor.extract_batch(documents)
# è¿”å›: {"æ–‡æ¡£1": [éœ€æ±‚åˆ—è¡¨], "æ–‡æ¡£2": [éœ€æ±‚åˆ—è¡¨], ...}
```

### è´¨é‡éªŒè¯

```python
quality_result = extractor.validate_extraction_quality(requirements)
print(f"è´¨é‡åˆ†æ•°: {quality_result['quality_score']:.2%}")
print(f"å‘ç°é—®é¢˜: {len(quality_result['issues'])} ä¸ª")
```

### éœ€æ±‚é›†åˆç®¡ç†

```python
collection = extractor.create_requirement_collection(requirements)
print(f"åŠŸèƒ½æ€§éœ€æ±‚: {collection.functional_count}")
print(f"éåŠŸèƒ½æ€§éœ€æ±‚: {collection.non_functional_count}")
```

## ğŸ› ï¸ é…ç½®é€‰é¡¹

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `provider` | AIProvider | OLLAMA | AIä¾›åº”å•† |
| `model` | str | qwen3:4b | æ¨¡å‹åç§° |
| `temperature` | float | 0.1 | æ¸©åº¦å‚æ•° |
| `ollama_url` | str | http://localhost:11434 | OllamaæœåŠ¡åœ°å€ |
| `openai_api_key` | str | None | OpenAI APIå¯†é’¥ |
| `google_api_key` | str | None | Google APIå¯†é’¥ |

## ğŸ› æ•…éšœæ’é™¤

### Ollamaç›¸å…³é—®é¢˜

1. **æ¨¡å‹æœªæ‰¾åˆ°**
   ```bash
   # æ£€æŸ¥å¯ç”¨æ¨¡å‹
   uv run python scripts/check_ollama_models.py
   
   # ä¸‹è½½æ¨¡å‹
   ollama pull qwen3:4b
   ```

2. **æœåŠ¡æœªè¿è¡Œ**
   ```bash
   # å¯åŠ¨OllamaæœåŠ¡
   ollama serve
   ```

### APIå¯†é’¥é—®é¢˜

1. **è®¾ç½®ç¯å¢ƒå˜é‡**
   ```bash
   export OPENAI_API_KEY="your-openai-key"
   export GOOGLE_API_KEY="your-google-key"
   ```

2. **ä»£ç ä¸­ç›´æ¥è®¾ç½®**
   ```python
   extractor = LangChainExtractor(
       provider=AIProvider.OPENAI,
       openai_api_key="your-key"
   )
   ```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [LangChainå®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- [Ollamaå®˜æ–¹æ–‡æ¡£](https://ollama.ai/)
- [é¡¹ç›®Sprint 2æŠ¥å‘Š](project-management/sprint2-langchain-integration.md)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ã€‚
